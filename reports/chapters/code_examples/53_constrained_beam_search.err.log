Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/asyncio/base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

tokenizer = AutoTokenizer.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

encoder_input_str = "translate English to German: How old are you?"

input_ids = tokenizer(encoder_input_str, return_tensors="pt").input_ids

outputs = model.generate(
    input_ids,
    num_beams=10,
    num_return_sequences=1,
    no_repeat_ngram_size=1,
    remove_invalid_values=True,
)

print("Output:\n" + 100 * '-')
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mImportError[0m                               Traceback (most recent call last)
Cell [0;32mIn[2], line 4[0m
[1;32m      1[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtransformers[39;00m [38;5;28;01mimport[39;00m AutoTokenizer, AutoModelForSeq2SeqLM
[1;32m      3[0m tokenizer [38;5;241m=[39m AutoTokenizer[38;5;241m.[39mfrom_pretrained([38;5;124m"[39m[38;5;124mt5-base[39m[38;5;124m"[39m)
[0;32m----> 4[0m model [38;5;241m=[39m [43mAutoModelForSeq2SeqLM[49m[38;5;241;43m.[39;49m[43mfrom_pretrained[49m([38;5;124m"[39m[38;5;124mt5-base[39m[38;5;124m"[39m)
[1;32m      6[0m encoder_input_str [38;5;241m=[39m [38;5;124m"[39m[38;5;124mtranslate English to German: How old are you?[39m[38;5;124m"[39m
[1;32m      8[0m input_ids [38;5;241m=[39m tokenizer(encoder_input_str, return_tensors[38;5;241m=[39m[38;5;124m"[39m[38;5;124mpt[39m[38;5;124m"[39m)[38;5;241m.[39minput_ids

File [0;32m/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/transformers/utils/import_utils.py:1093[0m, in [0;36mDummyObject.__getattribute__[0;34m(cls, key)[0m
[1;32m   1091[0m [38;5;28;01mif[39;00m key[38;5;241m.[39mstartswith([38;5;124m"[39m[38;5;124m_[39m[38;5;124m"[39m) [38;5;129;01mand[39;00m key [38;5;241m!=[39m [38;5;124m"[39m[38;5;124m_from_config[39m[38;5;124m"[39m:
[1;32m   1092[0m     [38;5;28;01mreturn[39;00m [38;5;28msuper[39m()[38;5;241m.[39m[38;5;21m__getattribute__[39m(key)
[0;32m-> 1093[0m [43mrequires_backends[49m[43m([49m[38;5;28;43mcls[39;49m[43m,[49m[43m [49m[38;5;28;43mcls[39;49m[38;5;241;43m.[39;49m[43m_backends[49m[43m)[49m

File [0;32m/opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/transformers/utils/import_utils.py:1081[0m, in [0;36mrequires_backends[0;34m(obj, backends)[0m
[1;32m   1079[0m failed [38;5;241m=[39m [msg[38;5;241m.[39mformat(name) [38;5;28;01mfor[39;00m available, msg [38;5;129;01min[39;00m checks [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m available()]
[1;32m   1080[0m [38;5;28;01mif[39;00m failed:
[0;32m-> 1081[0m     [38;5;28;01mraise[39;00m [38;5;167;01mImportError[39;00m([38;5;124m"[39m[38;5;124m"[39m[38;5;241m.[39mjoin(failed))

[0;31mImportError[0m: 
AutoModelForSeq2SeqLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.

ImportError: 
AutoModelForSeq2SeqLM requires the PyTorch library but it was not found in your environment. Checkout the instructions on the
installation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.
Please note that you may need to restart your runtime after installation.


